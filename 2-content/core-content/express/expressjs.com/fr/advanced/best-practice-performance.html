<!DOCTYPE html>

<html lang="fr" prefix="og: http://ogp.me/ns#">
<head>
<title>Meilleures pratiques en termes de performances pour l'utilisation d'Express en production</title>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="og:image" content="https://expressjs.com/images/express-facebook-share.png">
<link rel="icon" type="image/png" href="/images/favicon.png" />
<link rel="stylesheet" href="/css/style.css">
<link rel="stylesheet" href="/css/dropit.css">
<link rel="stylesheet" href="/css/prism.css">
<link rel="stylesheet" href="/css/font-awesome.min.css">
<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Open+Sans:300,400,600,700&amp;amp;subset=latin,latin-ext">
<link rel="stylesheet" href="/css/fr.css">
<link rel="stylesheet" href="/css/nodeinteractive.css">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<script data-cfasync="false" src="//ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>
<script data-cfasync="false" src="/js/ismobile.js"></script>
<script data-cfasync="false" src="/js/app.js"></script>
<script data-cfasync="false" src="/js/retina.js"></script>
<script data-cfasync="false" src="/js/dropit.js"></script>
<script data-cfasync="false" src="/js/prism.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
</head>
<body class="non-en-doc">
<section class="page content">
<header>
<div id="blm-banner">
Black Lives Matter. <br>
<a id="blm-donate" href="https://support.eji.org/give/153413/#!/donation/checkout">Support the Equal Justice Initiative</a>.
</div>
<div id="mobile-menu">
<div id="nav-button" class="fa fa-bars fa-2x button"></div>
</div>
<section id="logo"><a href="/" class="express">Express</a>
</section>
<div id="navbar">
<ul id="navmenu">
<input id="q" placeholder="üîé search">
<li><a href="/fr/" id="home-menu">Accueil</a></li>
<li>
<ul id="getting-started-menu" class="menu">
<li><a href="/fr/starter/installing.html">Mise en route</a>
<ul>
<li>
<a href="/fr/starter/installing.html">
Installation
</a>
</li>
<li>
<a href="/fr/starter/hello-world.html">
Hello world
</a>
</li>
<li>
<a href="/fr/starter/generator.html">
G√©n√©rateur Express
</a>
</li>
<li>
<a href="/fr/starter/basic-routing.html">
Routage de base
</a>
</li>
<li>
<a href="/fr/starter/static-files.html">
Fichiers statiques
</a>
</li>
<li>
<a href="/fr/starter/faq.html">
FAQ
</a>
</li>
</ul>
</li>
</ul>
</li>
<li>
<ul id="guide-menu" class="menu">
<li><a href="/fr/guide/routing.html">Guide</a>
<ul>
<li><a href="/fr/guide/routing.html">Routage</a>
</li>
<li><a href="/fr/guide/writing-middleware.html">Ecriture de middleware</a>
</li>
<li><a href="/fr/guide/using-middleware.html">Utilisation de middleware</a>
</li>
<li><a href="/fr/guide/using-template-engines.html">Utilisation de moteurs de mod√®les</a>
</li>
<li><a href="/fr/guide/error-handling.html">Traitement d'erreurs</a>
</li>
<li><a href="/fr/guide/debugging.html">D√©bogage</a>
</li>
<li><a href="/fr/guide/behind-proxies.html">Express derri√®re Proxys</a>
</li>
<li><a href="/fr/guide/migrating-4.html">Migration vers Express 4</a>
</li>
<li><a href="/fr/guide/migrating-5.html">Migration vers Express 5</a>
</li>
<li><a href="/fr/guide/database-integration.html">Int√©gration de bases de donn√©es</a>
</li>
</ul>
</li>
</ul>
</li>
<li>
<ul id="application-menu" class="menu">
<li><a href="/fr/4x/api.html">R√©f√©rence de l'API</a>
<ul>
<li><a href="/fr/4x/api.html">4.x</a>
</li>
<li><a href="/fr/3x/api.html">3.x (obsol√®te)</a>
</li>
<li><a href="/2x/">2.x (obsol√®te)</a>
</li>
</ul>
</li>
</ul>
</li>
<li>
<ul id="advanced-topics-menu" class="menu">
<li><a href="/fr/advanced/developing-template-engines.html" class="active">Rubriques avanc√©es</a>
<ul>
<li><a href="/fr/advanced/developing-template-engines.html">Moteurs de mod√®les</a>
</li>
<li><a href="/fr/advanced/pm.html">Utilisation de gestionnaires de processus</a>
</li>
<li><a href="/fr/advanced/security-updates.html">Mises √† jour de s√©curit√©</a>
</li>
<li><a href="/fr/advanced/best-practice-security.html">Meilleures pratiques en termes de s√©curit√©</a>
</li>
<li><a href="/fr/advanced/best-practice-performance.html">Meilleures pratiques en termes de performances</a>
</li>
</ul>
</li>
</ul>
</li>
<li>
<ul id="resources-menu" class="menu">
<li><a href="/fr/resources/glossary.html">Ressources</a>
<ul>
<li><a href="/fr/resources/glossary.html">Glossaire</a>
</li>
<li><a href="/fr/resources/middleware.html">Middleware</a>
</li>
<li><a href="/fr/resources/community.html">Communaut√©</a>
</li>
<li><a href="/fr/resources/learning.html">Apprentissage suppl√©mentaire</a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</header>
<div id="overlay"></div>
<div id="i18n-notice-box" class="doc-box doc-warn">
<p><p>Cette traduction fournie par <a href="http://strongloop.com">StrongLoop / IBM</a>.</p>
Il se peut que ce document soit obsol√®te par rapport √† la documentation en anglais. Pour conna√Ætre les mises √† jour les plus r√©centes, reportez-vous √† la <a href="/">documentation en anglais</a>.
</p>
<div id="close-i18n-notice-box" title="Close">‚úñ</div>
</div>
<div id="page-doc" markdown="1">
<h1 id="meilleures-pratiques-en-production--performances-et-fiabilit√©">Meilleures pratiques en production : performances et fiabilit√©</h1>
<h2 id="pr√©sentation">Pr√©sentation</h2>
<p>Cet article traite des meilleures pratiques en termes de performances et de fiabilit√© pour les applications Express d√©ploy√©es en production.</p>
<p>La pr√©sente rubrique s‚Äôinscrit clairement dans le concept ‚Äúdevops‚Äù, qui couvre √† la fois le d√©veloppement traditionnel et l‚Äôexploitation. Ainsi, les informations se divisent en deux parties :</p>
<ul>
<li><a href="#code">A faire dans votre code</a> (partie d√©veloppement, ‚Äúdev‚Äù).</li>
<li><a href="#env">A faire dans votre environnement/configuration</a> (partie exploitation, ‚Äúops‚Äù).</li>
</ul>
<p><a name="code"></a></p>
<h2 id="a-faire-dans-votre-code">A faire dans votre code</h2>
<p>Les actions suivantes peuvent √™tre r√©alis√©es dans votre code afin d‚Äôam√©liorer les performances de votre application :</p>
<ul>
<li>Utiliser la compression gzip</li>
<li>Ne pas utiliser les fonctions synchrones</li>
<li>Utiliser le middleware pour exploiter les fichiers statiques</li>
<li>Proc√©der √† une journalisation correcte</li>
<li>Traiter correctement les exceptions</li>
</ul>
<h3 id="utiliser-la-compression-gzip">Utiliser la compression gzip</h3>
<p>La compression Gzip peut consid√©rablement r√©duire la taille du corps de r√©ponse et ainsi augmenter la vitesse d‚Äôune application Web. Utilisez le middleware <a href="https://www.npmjs.com/package/compression">compression</a> pour la compression gzip dans votre application Express. Par exemple :</p>
<pre><code class="language-javascript" translate="no">
var compression = require('compression');
var express = require('express');
var app = express();
app.use(compression());
</code>
</pre>
<p>Pour un site Web en production dont le trafic est √©lev√©, la meilleure m√©thode pour mettre en place la compression consiste √† l‚Äôimpl√©menter au niveau d‚Äôun proxy inverse (voir <a href="#proxy">Utiliser un proxy inverse</a>). Dans ce cas, vous n‚Äôavez pas besoin d‚Äôutiliser le middleware compression. Pour plus de d√©tails sur l‚Äôactivation de la compression gzip dans Nginx, voir <a href="http://nginx.org/en/docs/http/ngx_http_gzip_module.html">Module ngx_http_gzip_module</a> dans la documentation Nginx.</p>
<h3 id="ne-pas-utiliser-les-fonctions-synchrones">Ne pas utiliser les fonctions synchrones</h3>
<p>Les fonctions et les m√©thodes synchrones ralentissent le processus d‚Äôex√©cution jusqu‚Äô√† leur retour. Un simple appel √† une fonction synchrone peut revenir en quelques microsecondes ou millisecondes ; pour les sites Web dont le trafic est √©lev√©, ces appels s‚Äôadditionnent et r√©duisent les performances de l‚Äôapplication. Evitez de les utiliser en production.</p>
<p>Bien que Node et plusieurs modules mettent √† disposition les versions synchrone et asynchrone de leurs fonctions, utilisez toujours la version asynchrone en production. L‚Äôutilisation d‚Äôune fonction synchrone n‚Äôest justifi√©e que lors du d√©marrage initial.</p>
<p>Si vous utilisez Node.js 4.0+ ou io.js 2.1.0+, vous pouvez utiliser l‚Äôoption de ligne de commande <code>--trace-sync-io</code> pour imprimer un avertissement et une trace de pile chaque fois que votre application utilise une API synchrone. Bien entendu vous n‚Äôutiliserez pas r√©ellement cette option en production, mais plut√¥t pour v√©rifier que votre code est pr√™t pour la phase production. Pour plus d‚Äôinformations, voir <a href="https://nodejs.org/en/blog/weekly-updates/weekly-update.2015-05-22/#2-1-0">Weekly update for io.js 2.1.0</a>.</p>
<h3 id="utiliser-le-middleware-pour-exploiter-les-fichiers-statiques">Utiliser le middleware pour exploiter les fichiers statiques</h3>
<p>En d√©veloppement, vous pouvez utiliser <a href="/fr/4x/api.html#res.sendFile">res.sendFile()</a> pour exploiter les fichiers statiques. Ne l‚Äôutilisez toutefois pas en production, car cette fonction doit lire le syst√®me de fichiers pour chaque demande de fichier ; elle se heurterait √† des temps d‚Äôattente importants qui affecteraient les performances globales de l‚Äôapplication. Notez que <code>res.sendFile()</code> n‚Äôest <em>pas</em> impl√©ment√©e avec l‚Äôappel syst√®me <a href="http://linux.die.net/man/2/sendfile">sendfile</a>, qui la rendrait beaucoup plus efficace.</p>
<p>Utilisez plut√¥t le middleware <a href="https://www.npmjs.com/package/serve-static">serve-static</a> (ou tout middleware √©quivalent), qui est optimis√© pour l‚Äôutilisation des fichiers dans les applications Express.</p>
<p>Encore mieux, utilisez un proxy inverse pour exploiter les fichiers statiques ; pour plus d‚Äôinformations, voir <a href="#proxy">Utiliser un proxy inverse</a>.</p>
<h3 id="proc√©der-√†-une-journalisation-correcte">Proc√©der √† une journalisation correcte</h3>
<p>En r√®gle g√©n√©rale, vous utilisez la journalisation √† partir de votre application √† deux fins : le d√©bogage et la journalisation de l‚Äôactivit√© de votre application (principalement tout le reste). L‚Äôutilisation de <code>console.log()</code> ou de <code>console.err()</code> pour imprimer des messages de journal sur le terminal est une pratique courante en d√©veloppement. Cependant, <a href="https://nodejs.org/api/console.html#console_console_1">ces fonctions sont synchrones</a> lorsque la destination est un terminal ou un fichier ; elles ne conviennent donc pas en production, √† moins que vous ne dirigiez la sortie vers un autre programme.</p>
<h4 id="pour-le-d√©bogage">Pour le d√©bogage</h4>
<p>Si vous utilisez la journalisation √† des fins de d√©bogage, utilisez un module de d√©bogage sp√©cial tel que <a href="https://www.npmjs.com/package/debug">debug</a> plut√¥t que d‚Äôutiliser <code>console.log()</code>. Ce module vous permet d‚Äôutiliser la variable d‚Äôenvironnement DEBUG pour contr√¥ler les messages de d√©bogage envoy√©s √† <code>console.err()</code>, le cas √©ch√©ant. Pour que votre application reste exclusivement asynchrone, vous devrez toujours diriger <code>console.err()</code> vers un autre programme. Mais bon, vous n‚Äôallez pas vraiment proc√©der √† un d√©bogage en production, n‚Äôest-ce pas ?</p>
<h4 id="pour-journaliser-lactivit√©-de-votre-application">Pour journaliser l‚Äôactivit√© de votre application</h4>
<p>Si vous journalisez l‚Äôactivit√© de votre application (par exemple, pour suivre le trafic ou les appels API), utilisez une biblioth√®que de journalisation telle que <a href="https://www.npmjs.com/package/winston">Winston</a> ou <a href="https://www.npmjs.com/package/bunyan">Bunyan</a> plut√¥t que d‚Äôutiliser <code>console.log()</code>. Pour obtenir une comparaison d√©taill√©e de ces deux biblioth√®ques, consultez l‚Äôarticle StrongLoop intitul√© <a href="https://strongloop.com/strongblog/compare-node-js-logging-winston-bunyan/">Comparing Winston and Bunyan Node.js Logging</a>.</p>
<p><a name="exceptions"></a></p>
<h3 id="traiter-correctement-les-exceptions">Traiter correctement les exceptions</h3>
<p>Les applications Node plantent lorsqu‚Äôelles tombent sur une exception non intercept√©e. Si vous ne traitez pas les exceptions et ne prenez pas les d√©cisions appropri√©es, votre application Express plantera et sera d√©connect√©e. Si vous suivez les conseils de la rubrique ci-dessous intitul√©e <a href="#restart">V√©rifier que votre application red√©marre automatiquement</a>, votre application pourra √™tre restaur√©e suite √† un plantage. Le d√©lai de d√©marrage des applications Express est heureusement court en r√®gle g√©n√©rale. Vous souhaitez toutefois √©viter tout plantage en priorit√© et pour ce faire, vous devez traiter les exceptions correctement.</p>
<p>Pour v√©rifier que vous traitez toutes les exceptions, proc√©dez comme suit :</p>
<ul>
<li><a href="#try-catch">Utiliser try-catch</a></li>
<li><a href="#promises">Utiliser des promesses</a></li>
</ul>
<p>Avant de s‚Äôimmerger dans les rubriques qui suivent, il est conseill√© de poss√©der des connaissances de base concernant le traitement des erreurs Node/Express, √† savoir l‚Äôutilisation des rappels ‚Äúerror-first‚Äù et la propagation des erreurs dans le middleware. Node utilise la convention de ‚Äúrappel error-first‚Äù pour renvoyer les erreurs issues des fonctions asynchrones, dans laquelle le premier param√®tre de la fonction callback est l‚Äôobjet error, suivi par les donn√©es de r√©sultat dans les param√®tres suivants. Pour n‚Äôindiquer aucune erreur, indiquez null comme premier param√®tre. La fonction de rappel doit suivre la convention de rappel ‚Äúerror-first‚Äù de sorte √† traiter l‚Äôerreur de mani√®re significative. Dans Express, la meilleure pratique consiste √† utiliser la fonction next() pour propager les erreurs via la cha√Æne du middleware.</p>
<p>Pour plus d‚Äôinformations sur les bases du traitement des erreurs, voir :</p>
<ul>
<li><a href="https://www.joyent.com/developers/node/design/errors">Error Handling in Node.js</a></li>
<li><a href="https://strongloop.com/strongblog/robust-node-applications-error-handling/">Building Robust Node Applications: Error Handling</a> (blogue StrongLoop)</li>
</ul>
<h4 id="a-ne-pas-faire">A ne pas faire</h4>
<p>Vous ne devriez <em>pas</em> √©couter l‚Äô√©v√©nement <code>uncaughtException</code>, √©mis lorsqu‚Äôune exception remonte vers la boucle d‚Äô√©v√©nements. L‚Äôajout d‚Äôun programme d‚Äô√©coute d‚Äô√©v√©nement pour <code>uncaughtException</code> va modifier le comportement par d√©faut du processus qui rencontre une exception ; le processus va continuer √† s‚Äôex√©cuter malgr√© l‚Äôexception. Cela pourrait √™tre un bon moyen d‚Äôemp√™cher votre application de planter, mais continuer √† ex√©cuter l‚Äôapplication apr√®s une exception non intercept√©e est une pratique dangereuse qui n‚Äôest pas recommand√©e, √©tant donn√© que l‚Äô√©tat du processus devient peu fiable et impr√©visible.</p>
<p>De plus, l‚Äôutilisation d‚Äô<code>uncaughtException</code> est officiellement reconnue comme √©tant <a href="https://nodejs.org/api/process.html#process_event_uncaughtexception">rudimentaire</a> et il a √©t√© <a href="https://github.com/nodejs/node-v0.x-archive/issues/2582">propos√©</a> de le supprimer. Ecouter <code>uncaughtException</code> n‚Äôest qu‚Äôune mauvaise id√©e. Voil√† pourquoi nous recommandons d‚Äôutiliser plusieurs processus et superviseurs √† la place : faire planter son application et la red√©marrer est souvent plus s√ªr que de la restaurer apr√®s une erreur.</p>
<p>L‚Äôutilisation de <a href="https://nodejs.org/api/domain.html">domain</a> n‚Äôest √©galement pas recommand√©e. Ce module obsol√®te ne r√©sout globalement pas le probl√®me.</p>
<p><a name="try-catch"></a></p>
<h4 id="utiliser-try-catch">Utiliser try-catch</h4>
<p>Try-catch est un √©l√©ment de langage JavaScript que vous pouvez utiliser pour intercepter les exceptions dans le code synchrone. Utilisez try-catch pour traiter les erreurs d‚Äôanalyse JSON, comme indiqu√© ci-dessous, par exemple.</p>
<p>Utilisez un outil tel que <a href="http://jshint.com/">JSHint</a> ou <a href="http://www.jslint.com/">JSLint</a> pour vous aider √† identifier les exceptions implicites comme les <a href="http://www.jshint.com/docs/options/#undef">erreurs de r√©f√©rence dans les variables non d√©finies</a>.</p>
<p>Voici un exemple d‚Äôutilisation de try-catch pour traiter une exception potentielle de plantage de processus.
Cette fonction middleware accepte un param√®tre de zone de requ√™te nomm√© ‚Äúparams‚Äù qui est un objet JSON.</p>
<pre><code class="language-javascript" translate="no">
app.get('/search', function (req, res) {
  // Simulating async operation
  setImmediate(function () {
    var jsonStr = req.query.params;
    try {
      var jsonObj = JSON.parse(jsonStr);
      res.send('Success');
    } catch (e) {
      res.status(400).send('Invalid JSON string');
    }
  });
});
</code>
</pre>
<p>Toutefois, try-catch ne fonctionne que dans le code synchrone. Etant donn√© que la plateforme Node est principalement asynchrone (en particulier dans un environnement de production), try-catch n‚Äôinterceptera pas beaucoup d‚Äôexceptions.</p>
<p><a name="promises"></a></p>
<h4 id="utiliser-des-promesses">Utiliser des promesses</h4>
<p>Les promesses vont traiter n‚Äôimporte quelle exception (explicite et implicite) dans les blocs de code asynchrone qui utilisent <code>then()</code>. Contentez-vous d‚Äôajouter <code>.catch(next)</code> √† la fin des cha√Ænes de promesse. Par exemple :</p>
<pre><code class="language-javascript" translate="no">
app.get('/', function (req, res, next) {
  // do some sync stuff
  queryDb()
    .then(function (data) {
      // handle data
      return makeCsv(data)
    })
    .then(function (csv) {
      // handle csv
    })
    .catch(next);
});

app.use(function (err, req, res, next) {
  // handle error
});
</code>
</pre>
<p>Toutes les erreurs asynchrones et synchrones sont √† pr√©sent propag√©es vers le middleware de traitement des erreurs.</p>
<p>Observez toutefois les deux avertissements suivants :</p>
<ol>
<li>L‚Äôint√©gralit√© de votre code asynchrone doit renvoyer des promesses (√† l‚Äôexception des √©metteurs). Si une biblioth√®que sp√©cifique ne renvoie pas de promesses, convertissez l‚Äôobjet de base √† l‚Äôaide d‚Äôune fonction d‚Äôaide telle que <a href="http://bluebirdjs.com/docs/api/promise.promisifyall.html">Bluebird.promisifyAll()</a>.</li>
<li>Les √©metteurs d‚Äô√©v√©nements (comme les flux) peuvent toujours g√©n√©rer des exceptions non intercept√©es. Veillez donc √† traiter l‚Äô√©v√©nement d‚Äôerreur de mani√®re appropri√©e ; par exemple :</li>
</ol>
<pre><code class="language-javascript" translate="no">
app.get('/', wrap(async (req, res, next) =&gt; {
  let company = await getCompanyById(req.query.id)
  let stream = getLogoStreamById(company.id)
  stream.on('error', next).pipe(res)
}))
</code>
</pre>
<p>Pour plus d‚Äôinformations sur le traitement des erreurs √† l‚Äôaide de promesses, voir :</p>
<ul>
<li><a href="https://strongloop.com/strongblog/async-error-handling-expressjs-es7-promises-generators/">Asynchronous Error Handling in Express with Promises, Generators and ES7</a></li>
<li><a href="https://strongloop.com/strongblog/promises-in-node-js-with-q-an-alternative-to-callbacks/">Promises in Node.js with Q ‚Äì An Alternative to Callbacks</a></li>
</ul>
<p><a name="env"></a></p>
<h2 id="a-faire-dans-votre-environnementconfiguration">A faire dans votre environnement/configuration</h2>
<p>Les actions suivantes peuvent √™tre r√©alis√©es dans votre environnement syst√®me afin d‚Äôam√©liorer les performances de votre application :</p>
<ul>
<li>D√©finir NODE_ENV sur ‚Äúproduction‚Äù</li>
<li>V√©rifier que votre application red√©marre automatiquement</li>
<li>Ex√©cuter votre application dans un cluster</li>
<li>Mettre en cache les r√©sultats d‚Äôune demande</li>
<li>Utiliser un √©quilibreur de charge</li>
<li>Utiliser un proxy inverse</li>
</ul>
<h3 id="d√©finir-node_env-sur-production">D√©finir NODE_ENV sur ‚Äúproduction‚Äù</h3>
<p>La variable d‚Äôenvironnement NODE_ENV sp√©cifie l‚Äôenvironnement dans lequel une application s‚Äôex√©cute (en r√®gle g√©n√©rale, d√©veloppement ou production). Le moyen le plus simple d‚Äôam√©liorer vos performances consiste √† d√©finir NODE_ENV sur ‚Äúproduction.‚Äù</p>
<p>En d√©finissant NODE_ENV sur ‚Äúproduction‚Äù, Express :</p>
<ul>
<li>Met en cache les mod√®les d‚Äôaffichage.</li>
<li>Met en cache les fichiers CSS g√©n√©r√©s √† partir d‚Äôextensions CSS.</li>
<li>G√©n√®re moins de messages d‚Äôerreur prolixes.</li>
</ul>
<p><a href="http://apmblog.dynatrace.com/2015/07/22/the-drastic-effects-of-omitting-node_env-in-your-express-js-applications/">Les tests indiquent</a> que ce simple param√©trage peut multiplier les performances d‚Äôapplication par trois !</p>
<p>Si vous avez besoin d‚Äô√©crire du code sp√©cifique √† un environnement, vous pouvez v√©rifier la valeur de NODE_ENV avec <code>process.env.NODE_ENV</code>. Sachez que la v√©rification de la valeur de n‚Äôimporte quelle variable d‚Äôenvironnement p√©nalise les performances et devrait donc √™tre effectu√©e avec mod√©ration.</p>
<p>En d√©veloppement, vous d√©finissez g√©n√©ralement les variables d‚Äôenvironnement dans votre shell interactif, √† l‚Äôaide de <code>export</code> ou de votre fichier <code>.bash_profile</code> par exemple. Il n‚Äôest toutefois pas conseill√© de le faire sur un serveur de production ; utilisez plut√¥t le syst√®me init de votre syst√®me d‚Äôexploitation (systemd ou Upstart). La section qui suit fournit des d√©tails sur l‚Äôutilisation de votre syst√®me init en g√©n√©ral, mais la d√©finition de NODE_ENV est tellement importante pour les performances (et facile √† r√©aliser), qu‚Äôelle est mise en √©vidence ici.</p>
<p>Avec Upstart, utilisez le mot cl√© <code>env</code> dans votre fichier de travail. Par exemple :</p>
<pre><code class="language-sh" translate="no">
# /etc/init/env.conf
 env NODE_ENV=production
</code>
</pre>
<p>Pour plus d‚Äôinformations, voir <a href="http://upstart.ubuntu.com/cookbook/#environment-variables">Upstart Intro, Cookbook and Best Practices</a>.</p>
<p>Avec systemd, utilisez la directive <code>Environment</code> dans votre fichier d‚Äôunit√©. Par exemple :</p>
<pre><code class="language-sh" translate="no">
# /etc/systemd/system/myservice.service
Environment=NODE_ENV=production
</code>
</pre>
<p>Pour plus d‚Äôinformations, voir <a href="https://coreos.com/os/docs/latest/using-environment-variables-in-systemd-units.html">Using Environment Variables In systemd Units</a>.</p>
<p>Si vous utilisez StrongLoop Process Manager, vous pouvez √©galement <a href="https://docs.strongloop.com/display/SLC/Setting+up+a+production+host#Settingupaproductionhost-Setenvironmentvariables">d√©finir la variable d‚Äôenvironnement lorsque vous installez StrongLoop PM en tant que service</a>.</p>
<h3 id="v√©rifier-que-votre-application-red√©marre-automatiquement">V√©rifier que votre application red√©marre automatiquement</h3>
<p>En production, vous ne souhaitez jamais que votre application soit d√©connect√©e. Vous devez donc veiller √† ce qu‚Äôelle red√©marre si elle plante et si le serveur plante. M√™me si vous esp√©rez que cela n‚Äôarrive pas, vous devez en r√©alit√© consid√©rer ces deux √©ventualit√©s en :</p>
<ul>
<li>Utilisant un gestionnaire de processus pour red√©marrer l‚Äôapplication (et Node) lorsqu‚Äôelle plante.</li>
<li>Utilisant le syst√®me init fourni par votre syst√®me d‚Äôexploitation pour red√©marrer le gestionnaire de processus lorsque le syst√®me d‚Äôexploitation plante. Vous pouvez √©galement utiliser le syst√®me init sans gestionnaire de processus.</li>
</ul>
<p>Les applications Node plantent si elles tombent sur une exception non intercept√©e. Avant toute chose, v√©rifiez que votre application est correctement test√©e et qu‚Äôelle traite toutes les exceptions (voir <a href="#exceptions">Traiter correctement les exceptions</a> pour plus de d√©tails). En cas d‚Äô√©chec, mettez en place un m√©canisme qui garantit que si et lorsque votre application plante, elle red√©marre automatiquement.</p>
<h4 id="utiliser-un-gestionnaire-de-processus">Utiliser un gestionnaire de processus</h4>
<p>En d√©veloppement, vous avez simplement d√©marr√© votre application √† partir de la ligne de commande avec <code>node server.js</code> ou une instruction similaire. En production, cela vous m√®nera droit au d√©sastre. Si l‚Äôapplication plante, elle sera d√©connect√©e tant que vous ne la red√©marrerez pas. Pour garantir que votre application red√©marre si elle plante, utilisez un gestionnaire de processus. Un gestionnaire de processus est un ‚Äúconteneur‚Äù d‚Äôapplications qui facilite le d√©ploiement, offre une haute disponibilit√© et vous permet de g√©rer l‚Äôapplication lors de son ex√©cution.</p>
<p>En plus de red√©marrer votre application lorsqu‚Äôelle plante, un gestionnaire de processus peut vous permettre :</p>
<ul>
<li>De vous informer sur les performances d‚Äôex√©cution et la consommation des ressources.</li>
<li>De modifier les param√®tres de mani√®re dynamique afin d‚Äôam√©liorer les performances.</li>
<li>De contr√¥ler la mise en cluster (StrongLoop PM et pm2).</li>
</ul>
<p>Les gestionnaires de processus les plus populaires pour Node sont les suivants :</p>
<ul>
<li><a href="http://strong-pm.io/">StrongLoop Process Manager</a></li>
<li><a href="https://github.com/Unitech/pm2">PM2</a></li>
<li><a href="https://www.npmjs.com/package/forever">Forever</a></li>
</ul>
<p>Pour obtenir une comparaison d√©taill√©e de ces trois gestionnaires de processus, voir <a href="http://strong-pm.io/compare/">http://strong-pm.io/compare/</a>. Pour obtenir une pr√©sentation d√©taill√©e, voir <a href="/fr/advanced/pm.html">Gestionnaires de processus pour les applications Express</a>.</p>
<p>L‚Äôutilisation de l‚Äôun de ces trois gestionnaires de processus suffira √† garder votre application active, m√™me si elle plantera de temps en temps.</p>
<p>StrongLoop PM poss√®de un grand nombre de fonctionnalit√©s qui ciblent en particulier le d√©ploiement en production. Vous pouvez l‚Äôutiliser avec les outils StrongLoop associ√©s pour :</p>
<ul>
<li>G√©n√©rer et mettre en package votre application en local, puis la d√©ployer en toute s√©curit√© sur votre syst√®me de production.</li>
<li>Red√©marrer automatiquement votre application si elle plante pour une raison quelconque.</li>
<li>G√©rer vos clusters √† distance.</li>
<li>Afficher les profils d‚ÄôUC et les instantan√©s de segment de m√©moire pour optimiser les performances et diagnostiquer les fuites de m√©moire.</li>
<li>Afficher les mesures de performance de votre application.</li>
<li>Evoluer facilement vers plusieurs h√¥tes avec un contr√¥l√© int√©gr√© de l‚Äô√©quilibreur de charge Nginx.</li>
</ul>
<p>Comme d√©crit ci-dessous, lorsque vous installez StrongLoop PM en tant que service de syst√®me d‚Äôexploitation √† l‚Äôaide de votre syst√®me init, il red√©marre automatiquement au red√©marrage du syst√®me. Ainsi, vos processus applicatifs et vos clusters resteront toujours actifs.</p>
<h4 id="utiliser-un-syst√®me-init">Utiliser un syst√®me init</h4>
<p>Le niveau de fiabilit√© suivant consiste √† garantir que votre application red√©marre lorsque le serveur red√©marre. Les syst√®mes peuvent toujours tomber en panne pour divers motifs. Pour garantir que votre application red√©marre si le serveur plante, utilisez le syst√®me init int√©gr√© √† votre syst√®me d‚Äôexploitation. Les deux principaux syst√®mes init actuellement utilis√©s sont <a href="https://wiki.debian.org/systemd">systemd</a> et <a href="http://upstart.ubuntu.com/">Upstart</a>.</p>
<p>Vous pouvez utiliser les syst√®mes init de deux mani√®res dans votre application Express :</p>
<ul>
<li>Ex√©cutez votre application dans un gestionnaire de processus, puis installez le gestionnaire de processus en tant que service avec le syst√®me init. Le gestionnaire de processus va red√©marrer votre application lorsqu‚Äôelle plantera et le syst√®me init va red√©marrer le gestionnaire de processus lorsque le syst√®me d‚Äôexploitation red√©marrera. Il s‚Äôagit de la m√©thode recommand√©e.</li>
<li>Ex√©cutez votre application (et Node) directement avec le syst√®me init. Cette m√©thode est plus simple, mais vous ne profitez pas des avantages d‚Äôun gestionnaire de processus.</li>
</ul>
<h5 id="systemd">Systemd</h5>
<p>Systemd est un syst√®me Linux et un gestionnaire de services. La plupart des distributions Linux principales ont adopt√© systemd comme leur syst√®me init par d√©faut.</p>
<p>Un fichier de configuration de service systemd est appel√© <em>fichier d‚Äôunit√©</em> et porte l‚Äôextension .service. Voici un exemple de fichier d‚Äôunit√© permettant de g√©rer une application Node directement (remplacez le texte en gras par les valeurs appropri√©es √† votre syst√®me et votre application) :</p>
<pre><code class="language-sh" translate="no">
[Unit]
Description=Awesome Express App

[Service]
Type=simple
ExecStart=/usr/local/bin/node /projects/myapp/index.js
WorkingDirectory=/projects/myapp

User=nobody
Group=nogroup

# Environment variables:
Environment=NODE_ENV=production

# Allow many incoming connections
LimitNOFILE=infinity

# Allow core dumps for debugging
LimitCORE=infinity

StandardInput=null
StandardOutput=syslog
StandardError=syslog
Restart=always

[Install]
WantedBy=multi-user.target
</code>
</pre>
<p>Pour plus d‚Äôinformations sur systemd, voir la <a href="http://www.freedesktop.org/software/systemd/man/systemd.unit.html">page d‚Äôaide de systemd</a>.</p>
<h5 id="strongloop-pm-en-tant-que-service-systemd">StrongLoop PM en tant que service systemd</h5>
<p>Vous pouvez facilement installer StrongLoop Process Manager en tant que service systemd. Une fois que c‚Äôest fait, lorsque le serveur red√©marre, il red√©marre automatiquement StrongLoop PM, qui red√©marre ensuite toutes les applications qu‚Äôil g√®re.</p>
<p>Pour installer StrongLoop PM en tant que service systemd :</p>
<pre><code class="language-sh" translate="no">
$ sudo sl-pm-install --systemd
</code>
</pre>
<p>D√©marrez ensuite le service comme suit :</p>
<pre><code class="language-sh" translate="no">
$ sudo /usr/bin/systemctl start strong-pm
</code>
</pre>
<p>Pour plus d‚Äôinformations, voir <a href="https://docs.strongloop.com/display/SLC/Setting+up+a+production+host#Settingupaproductionhost-RHEL7+,Ubuntu15.04or15.10">Setting up a production host</a> dans la documentation StrongLoop.</p>
<h5 id="upstart">Upstart</h5>
<p>Upstart est un outil syst√®me disponible sur un grand nombre de distributions Linux et qui permet de d√©marrer des t√¢ches et des services pendant le d√©marrage du syst√®me, de les arr√™ter pendant l‚Äôarr√™t du syst√®me et de les superviser. Vous pouvez configurer votre application Express ou votre gestionnaire de processus en tant que service, puis Upstart le red√©marrera automatiquement lorsqu‚Äôil plantera.</p>
<p>Un service Upstart est d√©fini dans un fichier de configuration de travail (√©galement appel√© ‚Äútravail‚Äù) portant l‚Äôextension <code>.conf</code>. L‚Äôexemple qui suit d√©crit comment cr√©er un travail appel√© ‚Äúmyapp‚Äù pour une application nomm√©e ‚Äúmyapp‚Äù avec le fichier principal situ√© dans <code>/projects/myapp/index.js</code>.</p>
<p>Cr√©ez un fichier nomm√© <code>myapp.conf</code> dans <code>/etc/init/</code> avec le contenu suivant (remplacez le texte en gras par les valeurs appropri√©es √† votre syst√®me et votre application) :</p>
<pre><code class="language-sh" translate="no">
# When to start the process
start on runlevel [2345]

# When to stop the process
stop on runlevel [016]

# Increase file descriptor limit to be able to handle more requests
limit nofile 50000 50000

# Use production mode
env NODE_ENV=production

# Run as www-data
setuid www-data
setgid www-data

# Run from inside the app dir
chdir /projects/myapp

# The process to start
exec /usr/local/bin/node /projects/myapp/index.js

# Restart the process if it is down
respawn

# Limit restart attempt to 10 times within 10 seconds
respawn limit 10 10
</code>
</pre>
<p>REMARQUE : ce script n√©cessite Upstart 1.4 ou ult√©rieur, pris en charge sur Ubuntu 12.04-14.10.</p>
<p>Etant donn√© que le travail est configur√© pour s‚Äôex√©cuter au d√©marrage du syst√®me, votre application sera d√©marr√©e avec le syst√®me d‚Äôexploitation et sera red√©marr√©e automatiquement si l‚Äôapplication plante ou si le syst√®me tombe en panne.</p>
<p>En plus de red√©marrer automatiquement l‚Äôapplication, Upstart vous permet d‚Äôutiliser les commandes suivantes :</p>
<ul>
<li><code>start myapp</code> ‚Äì D√©marre l‚Äôapplication</li>
<li><code>restart myapp</code> ‚Äì Red√©marre l‚Äôapplication</li>
<li><code>stop myapp</code> ‚Äì Arr√™te l‚Äôapplication</li>
</ul>
<p>Pour plus d‚Äôinformations sur Upstart, voir <a href="http://upstart.ubuntu.com/cookbook">Upstart Intro, Cookbook and Best Practises</a>.</p>
<h5 id="strongloop-pm-en-tant-que-service-upstart">StrongLoop PM en tant que service Upstart</h5>
<p>Vous pouvez facilement installer StrongLoop Process Manager en tant que service Upstart. Une fois que c‚Äôest fait, lorsque le serveur red√©marre, il red√©marre automatiquement StrongLoop PM, qui red√©marre ensuite toutes les applications qu‚Äôil g√®re.</p>
<p>Pour installer StrongLoop PM en tant que service Upstart 1.4 :</p>
<pre><code class="language-sh" translate="no">
$ sudo sl-pm-install
</code>
</pre>
<p>Ex√©cutez ensuite le service comme suit :</p>
<pre><code class="language-sh" translate="no">
$ sudo /sbin/initctl start strong-pm
</code>
</pre>
<p>REMARQUE : sur les syst√®mes qui ne prennent pas en charge Upstart 1.4, les commandes sont l√©g√®rement diff√©rentes. Pour plus d‚Äôinformations, voir <a href="https://docs.strongloop.com/display/SLC/Setting+up+a+production+host#Settingupaproductionhost-RHELLinux5and6,Ubuntu10.04-.10,11.04-.10">Setting up a production host</a> dans la documentation StrongLoop.</p>
<h3 id="ex√©cuter-votre-application-dans-un-cluster">Ex√©cuter votre application dans un cluster</h3>
<p>Dans un syst√®me multicoeur, vous pouvez augmenter les performances d‚Äôune application Node en lan√ßant un cluster de processus. Un cluster ex√©cute plusieurs instances de l‚Äôapplication, id√©alement une instance sur chaque coeur d‚ÄôUC, r√©partissant ainsi la charge et les t√¢ches entre les instances.</p>

<p>IMPORTANT : √©tant donn√© que les instances d‚Äôapplication s‚Äôex√©cutent en tant que processus distincts, elles ne partagent pas le m√™me espace m√©moire. Autrement dit, les objets sont en local sur chaque instance de l‚Äôapplication. Par cons√©quent, vous ne pouvez pas conserver l‚Äô√©tat dans le code de l‚Äôapplication. Vous pouvez toutefois utiliser un magasin de donn√©es en m√©moire tel que <a href="http://redis.io/">Redis</a> pour stocker les donn√©es de session et l‚Äô√©tat. Cette fonctionnalit√© s‚Äôapplique essentiellement √† toutes les formes de mise √† l‚Äô√©chelle horizontale, que la mise en cluster soit effectu√©e avec plusieurs processus ou avec plusieurs serveurs physiques.</p>
<p>Dans les applications mises en cluster, les processus de traitement peuvent planter individuellement sans impacter le reste des processus. Outre les avantages en termes de performance, l‚Äôisolement des pannes constitue une autre raison d‚Äôex√©cuter un cluster de processus d‚Äôapplication. Chaque fois qu‚Äôun processus de traitement plante, veillez toujours √† consigner l‚Äô√©v√©nement et √† g√©n√©ration un nouveau processus √† l‚Äôaide de cluster.fork().</p>
<h4 id="utilisation-du-module-cluster-de-node">Utilisation du module cluster de Node</h4>
<p>La mise en cluster peut √™tre r√©alis√©e avec le <a href="https://nodejs.org/docs/latest/api/cluster.html">module cluster</a> de Node. Ce module permet √† un processus ma√Ætre de g√©n√©rer des processus de traitement et de r√©partir les connexions entrantes parmi ces processus. Toutefois, plut√¥t que d‚Äôutiliser ce module directement, utilisez l‚Äôun des nombreux outils qui le font pour vous, √† savoir <a href="https://www.npmjs.com/package/node-pm">node-pm</a> ou <a href="https://www.npmjs.com/package/cluster-service">cluster-service</a> par exemple.</p>
<h4 id="utilisation-de-strongloop-pm">Utilisation de StrongLoop PM</h4>
<p>Si vous d√©ployez votre application dans StrongLoop Process Manager (PM), vous pouvez alors utiliser la mise en cluster <em>sans</em> modifier votre code d‚Äôapplication.</p>
<p>Lorsque StrongLoop Process Manager (PM) ex√©cute une application, il l‚Äôex√©cute automatiquement dans un cluster avec un nombre de processus de traitement √©gal au nombre de coeurs d‚ÄôUC sur le syst√®me. Vous pouvez modifier manuellement le nombre de processus de traitement dans le cluster √† l‚Äôaide de l‚Äôoutil de ligne de commande slc sans arr√™ter l‚Äôapplication.</p>
<p>Par exemple, en supposant que vous avez d√©ploy√© votre application sur prod.foo.com et que StrongLoop PM est en mode √©coute sur le port 8701 (par d√©faut), pour d√©finir la taille du cluster sur 8 √† l‚Äôaide de slc :</p>
<pre><code class="language-sh" translate="no">
$ slc ctl -C http://prod.foo.com:8701 set-size my-app 8
</code>
</pre>
<p>Pour plus d‚Äôinformations sur la mise en cluster avec StrongLoop PM, voir <a href="https://docs.strongloop.com/display/SLC/Clustering">Clustering</a> dans la documentation StrongLoop.</p>
<h3 id="mettre-en-cache-les-r√©sultats-dune-demande">Mettre en cache les r√©sultats d‚Äôune demande</h3>
<p>Pour am√©liorer les performances en production, vous pouvez √©galement mettre en cache le r√©sultat des demandes, de telle sorte que votre application ne r√©p√®te pas l‚Äôop√©ration de traitement de la m√™me demande plusieurs fois.</p>
<p>Utilisez un serveur de mise en cache tel que <a href="https://www.varnish-cache.org/">Varnish</a> ou <a href="https://www.nginx.com/resources/wiki/start/topics/examples/reverseproxycachingexample/">Nginx</a> (voir aussi <a href="https://serversforhackers.com/nginx-caching/">Nginx Caching</a>) pour am√©liorer consid√©rablement la vitesse et les performances de votre application.</p>
<h3 id="utiliser-un-√©quilibreur-de-charge">Utiliser un √©quilibreur de charge</h3>
<p>Quel que soit le niveau d‚Äôoptimisation d‚Äôune application, une instance unique ne peut traiter qu‚Äôun volume limit√© de charge et de trafic. Pour faire √©voluer une application, vous pouvez ex√©cuter plusieurs instances de cette application et r√©partir le trafic en utilisant un √©quilibreur de charge. La configuration d‚Äôun √©quilibreur de charge peut am√©liorer les performances et la vitesse de votre application et lui permettre d‚Äô√©voluer plus largement qu‚Äôavec une seule instance.</p>
<p>Un √©quilibreur de charge est g√©n√©ralement un proxy inverse qui orchestre le trafic entrant et sortant de plusieurs instances d‚Äôapplication et serveurs. Vous pouvez facilement configurer un √©quilibreur de charge pour votre application √† l‚Äôaide de <a href="http://nginx.org/en/docs/http/load_balancing.html">Nginx</a> ou de <a href="https://www.digitalocean.com/community/tutorials/an-introduction-to-haproxy-and-load-balancing-concepts">HAProxy</a>.</p>
<p>Avec l‚Äô√©quilibrage de charge, vous devrez peut-√™tre v√©rifier que les demandes associ√©es √† un ID de session sp√©cifique sont connect√©es au processus dont elles sont issues. Ce proc√©d√© est appel√© <em>affinit√© de session</em> (ou <em>sessions persistantes</em>) et peut √™tre effectu√© en utilisant un magasin de donn√©es tel que Redis pour les donn√©es de session (en fonction de votre application), comme d√©crit ci-dessus. Pour en savoir plus, voir <a href="http://socket.io/docs/using-multiple-nodes/">Using multiple nodes</a>.</p>
<h4 id="utilisation-de-strongloop-pm-avec-un-√©quilibreur-de-charge-nginx">Utilisation de StrongLoop PM avec un √©quilibreur de charge Nginx</h4>
<p><a href="http://strong-pm.io/">StrongLoop Process Manager</a> est int√©gr√© √† un contr√¥leur Nginx, ce qui permet de param√©trer facilement les configurations d‚Äôenvironnement de production √† plusieurs h√¥tes. Pour plus d‚Äôinformations, voir <a href="https://docs.strongloop.com/display/SLC/Scaling+to+multiple+servers">Scaling to multiple servers</a> (documentation StrongLoop).
<a name="proxy"></a></p>
<h3 id="utiliser-un-proxy-inverse">Utiliser un proxy inverse</h3>
<p>Un proxy inverse accompagne une application Web et ex√©cute des op√©rations de prise en charge sur les demandes, en plus de diriger les demandes vers l‚Äôapplication. Il peut g√©rer les pages d‚Äôerreur, la compression, la mise en cache, le d√©p√¥t de fichiers et l‚Äô√©quilibrage de charge entre autres.</p>
<p>La transmission de t√¢ches qui ne requi√®rent aucune connaissance de l‚Äô√©tat d‚Äôapplication √† un proxy inverse permet √† Express de r√©aliser des t√¢ches d‚Äôapplication sp√©cialis√©es. C‚Äôest pour cette raison qu‚Äôil est recommand√© d‚Äôex√©cuter Express derri√®re un proxy inverse tel que <a href="https://www.nginx.com/">Nginx</a> ou <a href="http://www.haproxy.org/">HAProxy</a> en production.</p>
</div>
</section>
<a id="top" href="#"><img src="/images/arrow.png"></a>
<footer>
<div id="footer-content">
<div id="github">
<iframe src="//ghbtns.com/github-btn.html?user=expressjs&amp;repo=express&amp;type=watch&amp;count=true" allowtransparency="true" frameborder="0" scrolling="0" width="110" height="20"></iframe>
</div>
<div id="sponsor"><a href="https://expressjs.com">Express</a> est un projet de la <a href="https://openjsf.org">Fondation OpenJS</a>.</div>
<div id="fork"><a href="https://github.com/expressjs/expressjs.com">Consultez le site Web GitHub</a>.</div>
<div>Copyright &copy; StrongLoop, Inc., et autres contributeurs expressjs.com.</div>
</div>
<div id="license">
<a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/us/"><img alt="Licence Creative Commons" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/3.0/us/80x15.png" /></a> Ce(tte) ≈ìuvre est mise √† disposition selon les termes de la <a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/us/">Licence Creative Commons Attribution - Partage dans les M√™mes Conditions 3.0 √âtats-Unis</a>.
</div>
</footer>
<script type="31a71a258ed093e2e7f69d3e-text/javascript" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js" onload="docsearch({
  apiKey: '7164e33055faa6ecddefd9e08fc59f5d',
  indexName: 'expressjs',
  inputSelector: '#q',
  algoliaOptions: { 'facetFilters': ['lang:fr'] }
})" async></script>
<script src="https://ajax.cloudflare.com/cdn-cgi/scripts/7089c43e/cloudflare-static/rocket-loader.min.js" data-cf-settings="31a71a258ed093e2e7f69d3e-|49" defer=""></script></body>
</html>
